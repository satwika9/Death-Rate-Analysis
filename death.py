# -*- coding: utf-8 -*-
"""death.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VHK86Pz4NnikNbPiLTqQpXQQ50sg_YOT
"""

import pandas as pd

death=pd.read_csv("death.csv")
death.head(10)

death.info()

# Data cleaning

# Checking null values
death.isnull()

# Identifying missing values(NaN -> Not a Number)
# How many NaN are there 
death.isna().sum()

# To fill null values using the specified value
death['day'].fillna(0, inplace=True)
death['day']=death['day'].astype(int)
death.tail()

# Checking null values
death.isna().sum()

#dropping a row with multiple missing values
death.dropna(inplace=True)
death.head(5)

#checking the null values 
death.isna().sum()

death['year']=death['year'].astype(int)
death['death']=death['death'].astype(int)
death.head(5)

# Data visualization

import matplotlib.pyplot as plt
import seaborn as sns

# Histogram
sns.histplot(data=death,x="causes" )
plt.title("Number of Causes", fontsize = 20)
plt.xlabel("Causes",fontsize=17)
plt.ylabel("Count", fontsize=17)
plt.xticks(size=15)
plt.show()

# Lineplot
sns.lineplot(x="year", y="causes", data=death)
sns.set_style("whitegrid")
#style white,dark,whitgrid,darkgrid
sns.set_context("notebook")
#context paper,poster,talk,notebook
plt.show()

# Bargraph
sns.barplot(x="death",y="state",ci=4, data=death)

#barplot

sns.barplot(x="causes", y="death", data=death )
plt.title("Number of deaths",fontsize=20)
plt.xlabel("Causes",fontsize=20)
plt.ylabel("Death",fontsize=20)
plt.xticks(rotation=45)
plt.yticks(size=15)
plt.show()

sns.barplot(x="gender", y="death", data=death )
plt.title("Number of Male and Female deaths ",fontsize=20)
plt.xlabel("Gender",fontsize=20)
plt.ylabel("Death",fontsize=20)
#plt.xticks(rotation=45)
plt.yticks(size=15)
plt.show()

# Heatmap
fig=plt.figure(figsize=(10,8))
sns.heatmap(death.corr() ,cmap='Blues' ,annot=True)

#Confusion matrix
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
X = death['death'].values  #independent variable
y = death['gender'].values   #dependent variable

X = X.reshape(-1,1)

X = X.reshape(-1,1)

X_train, X_test,  y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=0)

classifier=LogisticRegression(random_state=0)
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)

cm=confusion_matrix(y_test,y_pred)
print(cm)

ax=sns.heatmap(cm,annot=True,cmap='YlGnBu')
ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])
plt.show()

#Logistic regression analysis

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score
X = death['death'].values  #independent variable
y = death['gender'].values   #dependent variable

X = X.reshape(-1,1)

X_train, X_test,  y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=0)

classifier=LogisticRegression(random_state=0)
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)

cm=confusion_matrix(y_test,y_pred)
print(cm)

accuracies=cross_val_score(estimator=classifier,X=X_train,y=y_train,cv=10)
print(accuracies)
print("accuracy:{:.2f}%".format(accuracies.mean()*100))
print("standard deviation:{:.2f}%".format(accuracies.std()*100))

# Time series analysis using year

death.set_index("year", inplace = True)
death.head()

death.index

death.loc['1983'].head()

death.loc['1983':'1990']